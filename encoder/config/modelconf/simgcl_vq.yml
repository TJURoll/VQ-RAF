optimizer:
  name: adam
  lr: 1.0e-3
  weight_decay: 0
  load_model: simgcl
  mode: finetune # fix, all, finetune

train:
  epoch: 3000
  batch_size: 128
  save_model: true
  loss: pairwise
  test_step: 1
  reproducible: true
  seed: 256
  patience: 5

test:
  metrics: [recall, ndcg]
  k: [5, 10, 20]
  batch_size: 1024

data:
  type: general_cf
  name: amazon

model:
  name: simgcl_vq
  # general parameters here
  keep_rate: 1.0
  embedding_size: 256

  # dataset-specific hyper-parameter here
  layer_num: 3
  reg_weight: 1.0e-5
  cl_weight: 1.0e-1
  temperature: 0.2
  eps: 0.9
  kd_weight: 1.0e-1
  kd_temperature: 0.2
  # for amazon
  amazon:
    layer_num: 3
    reg_weight: 1.0e-5
    cl_weight: 1.0e-1
    temperature: 0.2
    eps: 0.9
    kd_weight: 1.0e-1
    kd_temperature: 0.2
  # for yelp
  yelp:
    layer_num: 3
    reg_weight: 1.0e-5
    cl_weight: 1.0e-1
    temperature: 0.2
    eps: 0.9
    kd_weight: 1.0e-1
    kd_temperature: 0.2
  # for steam
  steam:
    layer_num: 3
    reg_weight: 1.0e-5
    cl_weight: 1.0e-1
    temperature: 0.5
    eps: 0.2
    kd_weight: 1.0e-1
    kd_temperature: 0.2
